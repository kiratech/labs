{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: Modello ML di base con Dataset Meteo + Integrazione MLflow\n",
    "\n",
    "Benvenuto in questo laboratorio! Qui imparerai a:\n",
    "\n",
    "1. **Caricare e preparare un dataset meteo**, con dati di temperatura e umidità.\n",
    "2. **Addestrare un modello di Machine Learning** con Scikit-learn per prevedere la pioggia.\n",
    "3. **Valutare il modello** e comprendere i risultati.\n",
    "4. **Integrare MLflow** per tracciare metriche, parametri e versioni del modello.\n",
    "\n",
    "Seguiremo un approccio guidato, con spiegazioni dettagliate ad ogni passaggio.  \n",
    "La prima parte si concentra su Scikit-learn e il dataset meteo. La seconda parte estende il codice esistente con MLflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1: Dai Dati al Modello di Machine Learning (Supervised Learning con Scikit-learn)  \n",
    "\n",
    "### Obiettivo  \n",
    "Costruire un **modello di classificazione** che possa prevedere se pioverà, utilizzando come input i dati di **temperatura** e **umidità**. Il modello verrà addestrato con **Scikit-learn**, uno strumento potente per il Machine Learning in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preparazione del Dataset  \n",
    "\n",
    "Prima di addestrare un modello di Machine Learning, è fondamentale pulire i dati, perché valori mancanti o errati possono compromettere le previsioni. Un dataset ben preparato permette al modello di imparare meglio e fornire risultati più accurati.  \n",
    "\n",
    "Per questo laboratorio utilizzeremo un dataset di esempio:  \n",
    "[Weather Test Data](https://raw.githubusercontent.com/boradpreet/Weather_dataset/refs/heads/master/Weather%20Test%20Data.csv)  \n",
    "\n",
    "Il dataset **Weather Test Data** contiene informazioni meteorologiche raccolte in diversi momenti. Ogni riga rappresenta un'osservazione con parametri come **temperatura**, **umidità**, **pressione atmosferica** e altre variabili meteo.  \n",
    "\n",
    "L'obiettivo di questo dataset è analizzare i pattern climatici e utilizzarli per addestrare un modello di Machine Learning in grado di prevedere condizioni future, come la probabilità di pioggia o variazioni di temperatura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL del dataset \n",
    "url = \"https://raw.githubusercontent.com/boradpreet/Weather_dataset/refs/heads/master/Weather%20Test%20Data.csv\"\n",
    "\n",
    "# Caricamento del dataset in un dataframe Pandas\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Mostra le prime righe\n",
    "df.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Esplorazione e Pulizia dei Dati  \n",
    "\n",
    "Per garantire che il nostro modello funzioni correttamente, dobbiamo prima esaminare e preparare il dataset. Ecco i passaggi fondamentali:  \n",
    "\n",
    "1. **Controllo dei dati mancanti**: verifichiamo se ci sono valori assenti, poiché potrebbero compromettere l'addestramento del modello. Se necessario, possiamo eliminarli o sostituirli con valori appropriati.  \n",
    "2. **Conversione della colonna `Label`**: trasformiamo le categorie testuali (*NoRain* e *Rain*) in valori numerici (0 per *NoRain*, 1 per *Rain*), in modo che il modello possa interpretarli correttamente.  \n",
    "3. **Selezione delle feature principali**: scegliamo solo le colonne più rilevanti (es. temperatura e umidità) per semplificare il modello e migliorare le sue prestazioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Rimozione dei valori mancanti\n",
    "df = df.dropna()\n",
    "\n",
    "# 2. Conversione della colonna 'RainToday' in valori numerici\n",
    "df['RainToday'] = df['RainToday'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "# 3. Selezione delle feature \n",
    "features = ['MinTemp', 'MaxTemp', 'Humidity3pm', 'Humidity9am']\n",
    "\n",
    "X = df[features]\n",
    "y = df['RainToday']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Suddivisione del Dataset in Training e Test  \n",
    "\n",
    "Per addestrare e valutare correttamente il modello, dividiamo il dataset in due parti:  \n",
    "\n",
    "- **X (feature)**: contiene le informazioni che useremo per fare previsioni, come **temperatura** e **umidità**.  \n",
    "- **y (target)**: rappresenta la variabile che vogliamo prevedere, ovvero se pioverà (*Rain*) o meno (*NoRain*).  \n",
    "\n",
    "Dividiamo i dati in **training set** (80%) e **test set** (20%) per i seguenti motivi:  \n",
    "\n",
    "1. **Addestramento del modello**  \n",
    "   - L'80% dei dati viene usato per insegnare al modello a riconoscere i pattern tra le feature e il target.  \n",
    "\n",
    "2. **Valutazione del modello**  \n",
    "   - Il restante 20% dei dati non viene usato nell'addestramento, ma serve per testare il modello su dati mai visti prima.  \n",
    "   - Questo ci permette di capire se il modello è davvero in grado di fare previsioni accurate su nuovi dati.  \n",
    "\n",
    "3. **Evitare overfitting**  \n",
    "   - Se testassimo il modello sugli stessi dati con cui è stato addestrato, potremmo ottenere risultati ingannevolmente buoni, perché il modello li avrebbe semplicemente memorizzati.  \n",
    "   - Usare dati di test separati aiuta a verificare se il modello può generalizzare le sue previsioni a nuovi dati reali.  \n",
    "\n",
    "Questa suddivisione è un passaggio fondamentale per costruire un modello affidabile e capace di fare previsioni corrette su dati che non ha mai visto prima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Suddivisione dei dati (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"Dimensioni del dataset di training: {len(X_train)}\")\n",
    "print(f\"Dimensioni del dataset di test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Creazione e Addestramento del Modello  \n",
    "\n",
    "Ora che abbiamo preparato i dati, possiamo costruire e addestrare un modello di Machine Learning. Per questo utilizzeremo un classificatore chiamato [**RandomForestClassifier**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html), una delle tecniche più utilizzate per problemi di classificazione.  \n",
    "\n",
    "#### Perché usiamo **Random Forest**?  \n",
    "- È un modello basato su **alberi decisionali**, che suddivide i dati in più passaggi per prendere decisioni accurate.  \n",
    "- È **robusto** e gestisce bene sia dati numerici che categoriali.  \n",
    "- È meno sensibile ai dati rumorosi rispetto a un singolo albero decisionale, perché combina più alberi per migliorare la precisione.  \n",
    "\n",
    "Il modello verrà addestrato utilizzando i dati di **temperatura** e **umidità** per prevedere se ci sarà **pioggia** o meno. Dopo l'addestramento, lo testeremo su dati nuovi per valutarne l'accuratezza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Creazione e addestramento del modello\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Valutazione del Modello  \n",
    "\n",
    "Dopo aver addestrato il modello, dobbiamo verificare quanto è accurato nelle previsioni. Per farlo, calcoliamo **l'accuratezza** e altre metriche di valutazione.  \n",
    "\n",
    "#### Perché è importante valutare il modello?  \n",
    "Un modello di Machine Learning non è utile se non sappiamo quanto sia affidabile. La valutazione ci aiuta a capire:  \n",
    "- **Se il modello sta imparando correttamente dai dati** o se sta solo memorizzando le risposte (overfitting).  \n",
    "- **Se può essere utilizzato su dati nuovi** e fare previsioni realistiche.  \n",
    "\n",
    "#### Matrice di Confusione  \n",
    "Oltre all'accuratezza, utilizzeremo la **matrice di confusione**, un metodo visivo che mostra dove il modello fa previsioni corrette e dove sbaglia.  \n",
    "- Ci aiuta a individuare **falsi positivi** e **falsi negativi**, che sono errori critici in molti scenari reali.  \n",
    "- È utile per migliorare il modello, ad esempio regolando soglie di decisione o bilanciando i dati di input.  \n",
    "\n",
    "Con queste analisi possiamo capire se il nostro modello è pronto per essere utilizzato o se necessita di miglioramenti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Predizioni sul set di test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcolo dell'accuratezza ed f1-score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Accuratezza del modello: {accuracy:.2f}\")\n",
    "print(f\"F1-score del modello: {f1:.2f}\")\n",
    "\n",
    "# Report di classificazione\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Creiamo una heatmap con Seaborn\n",
    "target_names = [\"No Rain\", \"Rain\"]\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=target_names, yticklabels=target_names)\n",
    "\n",
    "# Aggiungiamo i titoli\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "\n",
    "# Mostriamo il grafico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusione (Parte 1)  \n",
    "\n",
    "In questa prima parte, abbiamo seguito un processo step-by-step per costruire un modello di Machine Learning in grado di prevedere la pioggia. Ecco cosa abbiamo fatto:  \n",
    "\n",
    "1. **Caricato il dataset meteo** per analizzare temperatura, umidità e altre variabili.  \n",
    "2. **Pulito e preparato i dati**, gestendo eventuali valori mancanti e trasformando la variabile target in un formato comprensibile al modello.  \n",
    "3. **Suddiviso il dataset** in dati di training (80%) e di test (20%) per addestrare e valutare il modello correttamente.  \n",
    "4. **Creato un modello di classificazione** utilizzando **RandomForestClassifier**, un algoritmo potente e robusto.  \n",
    "5. **Valutato le prestazioni del modello** calcolando l’accuratezza e analizzando la matrice di confusione per identificare eventuali errori.  \n",
    "\n",
    "Ora che abbiamo costruito il modello base, nella prossima parte esploreremo come integrare **MLflow** per tracciare gli esperimenti e migliorare ulteriormente le prestazioni."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tech: Installazione e Configurazione di MLflow  \n",
    "\n",
    "### Obiettivo  \n",
    "Configurare un'istanza locale di **MLflow** per registrare esperimenti, monitorare le metriche e gestire i modelli di Machine Learning in modo organizzato.  \n",
    "\n",
    "### 1. Avviare MLflow  \n",
    "\n",
    "Per avviare MLflow in locale, esegui il seguente comando nel terminale:  \n",
    "\n",
    "```bash\n",
    "    mlflow ui\n",
    "```\n",
    "\n",
    "Dopo averlo avviato, l'interfaccia grafica sarà accessibile all'indirizzo:  \n",
    "\n",
    "```\n",
    "    http://127.0.0.1:5000\n",
    "```\n",
    "\n",
    "Questa configurazione permette di **salvare esperimenti e modelli localmente**, consentendo di tracciare le diverse versioni dei modelli, confrontare le metriche di valutazione e ottimizzare i processi di addestramento.  \n",
    "\n",
    "Nelle prossime sezioni, vedremo come registrare parametri, metriche e modelli direttamente all'interno di MLflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLflow in Produzione  \n",
    "\n",
    "In ambienti di produzione e presso i clienti, **MLflow non viene eseguito in locale**, ma viene integrato in un'infrastruttura più solida e scalabile. Questo evita problemi legati alla gestione manuale degli esperimenti e alla persistenza dei dati.  \n",
    "\n",
    "Le soluzioni più comuni includono:  \n",
    "\n",
    "- **Docker Compose**  \n",
    "  - MLflow viene avviato utilizzando un file `docker-compose.yml`, che configura un database backend e uno storage remoto per salvare gli esperimenti.  \n",
    "  - Questo approccio è utile per ambienti controllati, dove è necessario un setup rapido e replicabile.  \n",
    "  - Un esempio di implementazione è disponibile nella repository interna:  \n",
    "    [kiratech/mlops-service-portfolio](https://github.com/kiratech/mlops-service-portfolio/tree/main).  \n",
    "\n",
    "- **Kubernetes (K8s)**  \n",
    "  - MLflow viene distribuito su un **cluster Kubernetes**, consentendo una gestione scalabile e centralizzata degli esperimenti.  \n",
    "  - Questo approccio è ideale per ambienti enterprise, dove sono richiesti elevati livelli di affidabilità, sicurezza e scalabilità.  \n",
    "\n",
    "Entrambe le soluzioni si basano su un'**architettura multi-container**, che include:  \n",
    "- **Un database persistente** (es. PostgreSQL o MySQL) per memorizzare i metadati degli esperimenti.  \n",
    "- **Uno storage S3 o MinIO** per salvare i modelli e gli artefatti, garantendo una gestione sicura e scalabile dei dati.  \n",
    "\n",
    "Questi approcci assicurano che MLflow possa essere utilizzato in modo affidabile in produzione, integrandosi con infrastrutture cloud o on-premise per una gestione efficace dei modelli di Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: Integrazione con MLflow  \n",
    "\n",
    "Ora estenderemo il codice esistente per **tracciare i nostri esperimenti** utilizzando **MLflow**. Questo ci permetterà di monitorare il processo di addestramento del modello, confrontare le diverse configurazioni e gestire le versioni del modello in modo strutturato.  \n",
    "\n",
    "### Perché integrare MLflow?  \n",
    "Con MLflow possiamo:  \n",
    "- **Registrare i parametri di addestramento** (es. `n_estimators` per Random Forest) per confrontare diverse configurazioni.  \n",
    "- **Salvare le metriche di valutazione** (es. accuratezza, F1-score) per monitorare le prestazioni del modello.  \n",
    "- **Archiviare il modello addestrato** per poterlo ricaricare facilmente in futuro e riutilizzarlo senza doverlo riaddestrare.  \n",
    "\n",
    "### Obiettivo  \n",
    "Integrare MLflow nel codice esistente per **tracciare e versionare i modelli**, registrando parametri, metriche e artefatti in modo strutturato.  \n",
    "\n",
    "### 1. Configurazione di MLflow  \n",
    "Prima di iniziare a tracciare gli esperimenti, impostiamo le variabili necessarie per utilizzare MLflow in questo progetto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Impostiamo un nome per l'esperimento\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"weather_classification_experiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifichiamo che dalla [nostra interfaccia grafica](http://127.0.0.1:5000) il nuovo esperimento sia visibile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Registrazione di Parametri, Metriche e Modello  \n",
    "\n",
    "Con **MLflow**, possiamo salvare e tracciare automaticamente diverse informazioni durante l'addestramento del modello. Questo ci aiuta a confrontare le performance tra diverse configurazioni e a recuperare facilmente i modelli migliori.  \n",
    "\n",
    "Ecco cosa possiamo registrare:  \n",
    "\n",
    "- **Parametri** → Valori utilizzati per configurare il modello, come `n_estimators` (numero di alberi in Random Forest) e altri iperparametri.  \n",
    "- **Metriche** → Indicatori delle prestazioni del modello, come **accuratezza**, **F1-score**, precisione e recall.  \n",
    "- **Modello** → La versione del modello addestrato, che potrà essere ricaricata e riutilizzata senza bisogno di riaddestramento.  \n",
    "\n",
    "Registrando questi elementi, possiamo analizzare e confrontare le diverse versioni del modello in modo strutturato e riproducibile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando il modello creato nella Parte 1\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "# Eseguiremo 4 esperimenti per addestrare più modelli \n",
    "n_estimators = [1, 10, 100, 500]\n",
    "\n",
    "for n_e in n_estimators:\n",
    "    # Creiamo una nuova run MLflow\n",
    "    with mlflow.start_run():\n",
    "        # Log Param\n",
    "        mlflow.log_param(\"n_estimators\", n_e)\n",
    "\n",
    "        # Creazione del modello\n",
    "        rf_model = RandomForestClassifier(n_estimators=n_e, random_state=42)\n",
    "        rf_model.fit(X_train, y_train)\n",
    "\n",
    "        # Calcolo metriche\n",
    "        y_pred = rf_model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"f1\", f1)\n",
    "\n",
    "        # Creiamo una heatmap con Seaborn\n",
    "        target_names = [\"No Rain\", \"Rain\"]\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=target_names, yticklabels=target_names)\n",
    "\n",
    "        # Aggiungiamo i titoli\n",
    "        plt.xlabel(\"Predicted Label\")\n",
    "        plt.ylabel(\"True Label\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "\n",
    "        # Salviamo l'immagine come PNG\n",
    "        if not os.path.exists(\"dev/\"):\n",
    "            os.makedirs(\"dev/\")\n",
    "        plt.savefig(\"dev/confusion_matrix.png\")\n",
    "        plt.close()\n",
    "        # Salviamo la confusion matrix su MLFlow come artifatto\n",
    "        mlflow.log_artifact(\"dev/confusion_matrix.png\")\n",
    "\n",
    "        # Salviamo il modello\n",
    "        example_dict = {'MinTemp': 1.1, 'MaxTemp': 1.1, 'Humidity3pm': 1.1, 'Humidity9am': 1.1}\n",
    "        signature = infer_signature(model_input=example_dict)\n",
    "        mlflow.sklearn.log_model(rf_model, \"random_forest_model\", signature=signature)\n",
    "\n",
    "        print(f\"Esperimento concluso. Accuratezza registrata: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Visualizzazione e Confronto dei Risultati  \n",
    "\n",
    "Dopo aver registrato i parametri, le metriche e i modelli, possiamo utilizzare **MLflow** per esplorare e confrontare i diversi esperimenti.  \n",
    "\n",
    "MLflow fornisce un’interfaccia web accessibile all’indirizzo:  \n",
    "\n",
    "```bash\n",
    "    http://127.0.0.1:5000\n",
    "```\n",
    "\n",
    "Accedendo a questa interfaccia, nella sezione **Experiments**, sarà possibile:  \n",
    "- **Esaminare i parametri** utilizzati in ogni esperimento.  \n",
    "- **Confrontare le metriche** tra diverse configurazioni di modello.  \n",
    "- **Visualizzare e scaricare i modelli salvati**, facilitando il riutilizzo e il deployment.  \n",
    "\n",
    "Questa funzionalità consente di monitorare l’evoluzione delle performance del modello e di identificare rapidamente le configurazioni migliori."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Caricare un Modello Salvato con MLflow  \n",
    "\n",
    "MLflow consente di salvare e ricaricare facilmente i modelli addestrati, evitando la necessità di riaddestrarli ogni volta.  \n",
    "\n",
    "Per recuperare un modello salvato in MLflow, è necessario copiare **l'ID della run** dell'esperimento eseguito. Questo ID identifica in modo univoco ogni esperimento registrato e permette di caricare il modello corrispondente per effettuare previsioni future.  \n",
    "\n",
    "Questa funzionalità è particolarmente utile per:  \n",
    "- **Riutilizzare un modello addestrato** senza dover ripetere il training.  \n",
    "- **Confrontare diverse versioni** di un modello per scegliere quella più performante.  \n",
    "- **Integrare il modello in applicazioni o API**, senza doverlo ricostruire da zero.  \n",
    "\n",
    "Nelle prossime sezioni vedremo come eseguire questo processo in pratica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Inserisci un run_id reale che trovi nell'interfaccia MLflow\n",
    "RUN_ID = \"<run_id_della_tua_run>\"\n",
    "\n",
    "loaded_model = mlflow.sklearn.load_model(f\"runs:/{RUN_ID}/random_forest_model\")\n",
    "\n",
    "# Verifichiamo l'accuratezza\n",
    "y_loaded_pred = loaded_model.predict(X_test)\n",
    "acc_loaded = accuracy_score(y_test, y_loaded_pred)\n",
    "print(f\"Accuratezza del modello caricato: {acc_loaded:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusioni  \n",
    "\n",
    "In questo laboratorio, abbiamo seguito un processo completo per costruire e monitorare un modello di Machine Learning applicato ai dati meteorologici. In particolare, abbiamo:  \n",
    "\n",
    "1. **Creato un modello di classificazione** utilizzando **Scikit-learn**, sfruttando temperatura e umidità per prevedere la pioggia.  \n",
    "2. **Integrato MLflow** per tracciare i parametri di addestramento, registrare le metriche di valutazione e gestire le versioni del modello in modo strutturato.  \n",
    "3. **Esplorato e confrontato i risultati** attraverso l’interfaccia di MLflow UI, verificando le diverse configurazioni e caricando un modello salvato per future previsioni.  \n",
    "\n",
    "Questo approccio ci permette di migliorare il processo di sviluppo dei modelli di Machine Learning, rendendolo più organizzato, riproducibile e scalabile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prossimi Passi  \n",
    "\n",
    "Ora che abbiamo costruito e tracciato il nostro modello, possiamo esplorare ulteriori miglioramenti e integrare il lavoro in un flusso più avanzato.  \n",
    "\n",
    "- **Ottimizzazione degli iperparametri**: testare diverse configurazioni di `n_estimators`, `max_depth` e altri parametri del modello, registrando i risultati in **MLflow** per identificare la combinazione migliore.  \n",
    "- **Automazione con CI/CD**: integrare un sistema di **Continuous Integration/Continuous Deployment (CI/CD)** per addestrare e distribuire automaticamente nuove versioni del modello, riducendo il rischio di errori manuali.  \n",
    "- **Monitoraggio del modello in produzione**: implementare un sistema di **monitoraggio del drift del modello**, per rilevare eventuali cali di accuratezza nel tempo e decidere quando è necessario riaddestrarlo con nuovi dati.  \n",
    "\n",
    "Questi passaggi aiutano a trasformare il modello sviluppato in un sistema robusto e affidabile, pronto per essere utilizzato in scenari reali."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.9 ('lab_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fbd6de99d3dee89886aa6f30475b6b26f6fe2ef531b8e041d1262739f0fd6851"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
